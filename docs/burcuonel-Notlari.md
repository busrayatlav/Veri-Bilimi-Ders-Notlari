# Makine Öğrenmesi Nedir?

Makine öğrenimi (ML), bilgisayarların ve makinelerin insanların öğrenme biçimini taklit etmelerini, görevleri özerk bir şekilde yerine getirmelerini ve deneyim ve daha fazla veriye maruz kalma yoluyla performanslarını ve doğruluklarını artırmalarını sağlamaya odaklanan yapay zekanın bir dalıdır.

## Makine öğrenme yöntemleri

Makine öğrenimi modelleri üç temel kategoriye ayrılır.

### 1-) Gözetimli öğrenme

Gözetimli öğrenme, gözetimli makine öğrenimi olarak da bilinir, algoritmaları verileri sınıflandırmak veya sonuçları doğru bir şekilde tahmin etmek için eğitmek amacıyla etiketli veri kümelerinin kullanımıyla tanımlanır. Giriş verileri modele beslendiğinde, model uygun şekilde uyuşana kadar ağırlıklarını ayarlar. Bu, modelin aşırı uyumu veya yetersiz uyumu önlemesini sağlamak için çapraz doğrulama sürecinin bir parçası olarak gerçekleşir. Gözetimli öğrenme, kuruluşların gelen kutunuzdan ayrı bir klasörde spam sınıflandırmak gibi çeşitli gerçek dünya sorunlarını büyük ölçekte çözmelerine yardımcı olur. Gözetimli öğrenmede kullanılan bazı yöntemler arasında sinir ağları, Naïve Bayes, doğrusal regresyon, lojistik regresyon, rastgele orman ve destek vektör makinesi (SVM) bulunur.

### 2-) Gözetimsiz öğrenme

Gözetimsiz öğrenme, gözetimsiz makine öğrenimi olarak da bilinir, etiketlenmemiş veri kümelerini (kümeler adı verilen alt kümeler) analiz etmek ve kümelemek için makine öğrenimi algoritmalarını kullanır. Bu algoritmalar, insan müdahalesine ihtiyaç duymadan gizli kalıpları veya veri gruplarını keşfeder.

Gözetimsiz öğrenmenin bilgideki benzerlikleri ve farklılıkları keşfetme yeteneği, onu keşifsel veri analizi, çapraz satış stratejileri, müşteri segmentasyonu ve görüntü ve desen tanıma için ideal hale getirir. Ayrıca, boyut azaltma süreciyle bir modeldeki özellik sayısını azaltmak için kullanılır. Temel bileşen analizi (PCA) ve tekil değer ayrıştırma (SVD) bunun için iki yaygın yaklaşımdır. Gözetimsiz öğrenmede kullanılan diğer algoritmalar arasında sinir ağları, k-ortalamalar kümeleme ve olasılıksal kümeleme yöntemleri bulunur.

### 3-) Yarı-denetimli öğrenme

Yarı-denetimli öğrenme, denetlenen ve denetlenmeyen öğrenme arasında mutlu bir ortam sunar. Eğitim sırasında, daha büyük, etiketlenmemiş bir veri kümesinden sınıflandırma ve özellik çıkarmayı yönlendirmek için daha küçük bir etiketli veri kümesi kullanır. Yarı-denetimli öğrenme, denetlenen bir öğrenme algoritması için yeterli etiketli veri olmaması sorununu çözebilir. Ayrıca, yeterli veriyi etiketlemek çok maliyetliyse yardımcı olur.

### 4-) Takviyeli öğrenme

Güçlendirmeli öğrenme, denetlenen öğrenmeye benzer bir makine öğrenme modelidir, ancak algoritma örnek veriler kullanılarak eğitilmez. Bu model deneme yanılma yoluyla ilerlerken öğrenir. Başarılı sonuçlar dizisi, belirli bir sorun için en iyi öneriyi veya politikayı geliştirmek üzere güçlendirilecektir.

## Yaygın makine öğrenme algoritmaları

Bir dizi makine öğrenme algoritması yaygın olarak kullanılır. Bunlar şunları içerir:

1. Sinir ağları
2. Doğrusal regresyon
3. Lojistik regresyon
4. Kümeleme
5. Karar ağaçları
6. Rastgele ormanlar

### Sinir ağları

Sinir ağları, çok sayıda bağlı işlem düğümüyle insan beyninin çalışma şeklini simüle eder. Sinir ağları, desenleri tanımada iyidir ve doğal dil çevirisi, görüntü tanıma, konuşma tanıma ve görüntü oluşturma gibi uygulamalarda önemli bir rol oynar.

### Doğrusal Regresyon (Lineer Regresyon)

Bu algoritma, farklı değerler arasındaki doğrusal ilişkiye dayalı olarak sayısal değerleri tahmin etmek için kullanılır. Örneğin, teknik, bölge için geçmiş verilere dayalı olarak ev fiyatlarını tahmin etmek için kullanılabilir.

### Lojistik Regresyon (Lojistik Regresyon)

Bu denetlenen öğrenme algoritması, sorulara "evet/hayır" yanıtları gibi kategorik yanıt değişkenleri için tahminlerde bulunur. Spam sınıflandırma ve üretim hattında kalite kontrolü gibi uygulamalar için kullanılabilir.

### Kümeleme (Clustering)

Denetimsiz öğrenmeyi kullanarak, kümeleme algoritmaları verilerdeki kalıpları belirleyebilir, böylece veriler gruplandırılabilir. Bilgisayarlar, insanların gözden kaçırdığı veri öğeleri arasındaki farklılıkları belirleyerek veri bilimcilere yardımcı olabilir.

### Karar Ağaçları (Decision Trees)

Karar ağaçları hem sayısal değerleri tahmin etmek (regresyon) hem de verileri kategorilere ayırmak için kullanılabilir. Karar ağaçları, bir ağaç diyagramıyla temsil edilebilen, bağlantılı kararların dallanan bir dizisini kullanır. Karar ağaçlarının avantajlarından biri, sinir ağının kara kutusunun aksine, doğrulanmasının ve denetlenmesinin kolay olmasıdır.

### Rastgele Ormanlar (Random Forest)

Rastgele bir ormanda, makine öğrenmesi algoritması, bir dizi karar ağacından gelen sonuçları birleştirerek bir değeri veya kategoriyi tahmin eder.

## Kaynakça

https://www.ibm.com/think/topics/machine-learning

---
---
# Neural Networks: Yapay Zekanın Beyni

Neural Networks (Sinir Ağları), yapay zeka ve makine öğrenmesinin temel yapı taşlarından biridir. İnsan beyninin işleyişinden ilham alınarak tasarlanan bu yapılar, karmaşık problemlerin çözümünde ve veri işleme süreçlerinde kullanılır. Özellikle günümüzün yapay zeka devriminde, sinir ağları, deep learning, generative AI ve diğer birçok modelin temelini oluşturur.

Neural networks, insan beynindeki sinir hücrelerinden esinlenerek tasarlanmış bir yapıdır. İnsan beyninde milyarlarca nöron, birbirleriyle sinapslar aracılığıyla etkileşimde bulunur ve bilgi iletir. Benzer şekilde, bir yapay sinir ağı da bir dizi "nöron" (yapay nöron) veya "katman" aracılığıyla bilgiyi işler.

Bu ağlar, veri girdilerini alır, bu verileri işler ve sonunda bir çıktı üretir. Neural networks, öğrenme sürecinde ağırlıklar ve bağlanma kuvvetlerini optimize ederek girdilere dayalı sonuçlar üretir. Bu ağlar özellikle büyük veri setleri ile eğitildiğinde, karmaşık ilişkileri ve örüntüleri öğrenme yeteneğine sahiptir.

## Neural Networks Nasıl Çalışır?

Sinir ağları, katmanlar halinde organize edilir. Bu katmanlar üç ana başlık altında incelenir:

1. **Giriş Katmanı (Input Layer)**: Bu katman, modele giren verileri alır. Örneğin, bir resim sınıflandırma probleminde resmin piksel değerleri bu katman tarafından alınır.

2. **Gizli Katmanlar (Hidden Layers)**: Giriş katmanından alınan veriler, bir veya daha fazla gizli katmandan geçer. Bu katmanlar, verileri işleyip modelin öğrenmesi gereken özellikleri çıkarır. Daha derin sinir ağlarında (örneğin, Deep Neural Networks), birçok gizli katman bulunur.

3. **Çıkış Katmanı (Output Layer)**: Gizli katmanlardan gelen bilgiler, çıkış katmanında işlenir ve son karar burada verilir. Örneğin, bir görüntü tanıma sistemi bir resmin "kedi" veya "köpek" olduğunu çıkış katmanında belirler.

Sinir ağları, backpropagation yöntemi ile öğrenir. Yani, modelin ürettiği hatalar geri besleme yoluyla ağırlıklara iletilir ve bu ağırlıklar güncellenir. Böylece model, zamanla daha doğru sonuçlar üretmeyi öğrenir.

## Neural Networks Türleri

Farklı problem türlerine göre neural networks farklı yapılar alabilir. İşte en yaygın neural networks türleri:

### 1. Feedforward Neural Networks (FFNN)

En temel sinir ağı yapısıdır. Veriler, giriş katmanından çıkış katmanına doğru ilerler ve geri dönmez. Bu tür ağlar, genellikle basit sınıflandırma ve regresyon problemlerinde kullanılır. Autoregressive models gibi ardışık veri gerektirmeyen yapılarda kullanılabilir.

### 2. Convolutional Neural Networks (CNNs)

CNN'ler özellikle görüntü işleme problemlerinde yaygın olarak kullanılır. Verilerin bölgesel özelliklerini çıkarmak için katmanlar arası "convolution" işlemi uygulanır. Generative Adversarial Networks (GANs) gibi görsel veri üreten yapılar, CNN yapılarından yararlanır.

### 3. Recurrent Neural Networks (RNNs)

RNN'ler, ardışık veri işleme ve zaman serileri tahmini gibi problemlerde kullanılır. Özellikle dil modellerinde, bir kelimenin sırasının önemli olduğu yerlerde kullanılır. RNN'ler geçmiş verileri hatırlayabilen ve bu verilere göre tahminler yapabilen bir yapıya sahiptir. GPT (Generative Pre-trained Transformer) gibi modeller, bu tür ağların geliştirilmiş versiyonlarına dayanır.

### 4. Transformer Neural Networks

Transformer neural networks, özellikle dil işleme ve metin üretimi gibi alanlarda kullanılan en yeni yapılar arasındadır. Attention mechanism adı verilen bir yapıyı kullanarak veriler arasındaki ilişkileri öğrenir. Bu modeller, Few-shot learning ve Zero-shot learning gibi uygulamalarda üstün performans sergiler.

## Öğrenme Algoritmalarına Göre Yapay Sinir Ağları

Yapay sinir ağları öğrenme ile ilgili algoritmalar göre üç başlıkta gruplandırılır:

1. **Danışmanlı öğrenme**: Öğrenme aşamasında sisteme giren verilerin nasıl çıktı vereceği bilgisi en başta öğretilir. Buna göre çıktı vermesi beklenir. Yapay sinir ağı istenilen çıktıyı vermezse hata payı hesaplanır ve sistemin ağırlık değeri buna göre güncellenir.

2. **Danışmansız öğrenme**: Öğrenme aşamasında sadece örnek girdiler tanımlanır. Sistemin kendi kurallarını oluşturması beklenir.

3. **Destekleyici öğrenme**: Öğrenme aşamasında sistemin her verdiği çıktıya dışarıdan iyi-kötü gibi iki değere göre değerlendirme yapılır. Sistemin en uygun çıktıyı bulmasına destek verilir.

## Öğrenme Zamanına Göre Yapay Sinir Ağları

Yapay sinir ağları öğrenme zamanına göre iki başlıkta gruplandırılır:

1. **Statik öğrenme**: Yapay sinir ağı modeli kullanılmadan önce eğitilir. Öğrenme süreci tamamlandıktan sonra kullanıma açılır. Kullanım esnasında çalışma sistemine müdahale edilmez.

2. **Dinamik öğrenme**: Yapay sinir ağı modeli kullanım esnasında da öğrenme sürecinin devam ettiği modellerdir.

## Kaynakça

- https://www.komtas.com/glossary/neural-networks-nedir
- https://www.techcareer.net/dictionary/neural-network

---
---
# K-Means

## K-Means Nedir?
- K-ortalamalar kümeleme, etiketlenmemiş veri noktalarını gruplara veya kümelere ayıran, veri kümeleme için kullanılan gözetimsiz bir öğrenme algoritmasıdır.
- Özel, örtüşen, hiyerarşik ve olasılıksal olmak üzere çeşitli kümeleme algoritmaları mevcut olsa da, k-ortalamalar kümeleme algoritması özel veya "sert" kümeleme yönteminin bir örneğidir.
- Bu gruplama biçimi, bir veri noktasının yalnızca bir kümede bulunabileceğini şart koşar.
- K-means, bir veri kümesini merkezleri arasındaki mesafeye göre benzer gruplara ayıran yinelemeli, merkez tabanlı bir kümeleme algoritmasıdır.
- Merkez veya küme merkezi, verilerin özelliklerine bağlı olarak küme içindeki tüm noktaların ortalaması veya medyanıdır.

## K-Means Nasıl Çalışır?
- K-ortalama kümeleme, veri noktaları ile küme merkezleri arasındaki uzaklıkların toplamını en aza indirmek için uygulanan yinelemeli bir işlemdir.
- K-ortalamalar kümeleme algoritması, küme merkezinden genellikle Öklidsel olan matematiksel bir mesafe ölçüsü kullanarak veri noktalarını kümelere ayırarak çalışır.
- Amaç, veri noktaları ile atanmış kümeleri arasındaki mesafelerin toplamını en aza indirmektir.

## Küme Değerlendirme Metrikleri Nelerdir?
Kalite kümeleri en az iki özelliği içerir:
1. Bir küme içindeki tüm veri noktaları benzer olmalıdır.
2. Kümelerin birbirinden farklı olması gerekir.

## En Uygun Küme Sayısının Seçilmesi için Yöntemler
İdeal olarak, k-ortalamalar algoritması, optimum küme sayısına ulaşılana kadar yineleme yapar. Maksimum yineleme sayısına, merkezler yakınsamaya ulaştığında ulaşılır.

### Dirsek Yöntemi
En uygun küme sayısına ulaşmak için bir yöntem dirsek yöntemidir. Dirsek yöntemi, k-ortalama kümeleme algoritması içinde en uygun küme sayısını bulmak için kullanılan grafiksel bir yöntemdir. Her veri noktası ile küme merkezi arasındaki Öklid uzaklığını ölçer ve küme sayısını "küme içi kareler toplamı"ndaki (WCSS) değişimin nerede dengelendiğine göre seçer.

Bu yöntem, özellikle yüksek boyutlu veya düzensiz şekilli veri kümeleri için mutlaka en iyisi değildir. Optimum küme sayısını seçmek için bir diğer yöntem de silüet analizidir.

## Kaynakça
https://www.ibm.com/think/topics/k-means-clustering

---
---

# Backpropagation

## Neural Networks'ün Öğrenme Sürecini Anlamak

- **Backpropagation (geri yayılım)**, yapay sinir ağlarının öğrenme sürecinde kullanılan temel bir algoritmadır. Bu algoritma, sinir ağlarının bir problemi çözmek için gerekli ağırlıkları nasıl optimize edeceğini öğrenmesini sağlar.
- Yapay zeka ve derin öğrenme alanında, backpropagation, sinir ağlarının hatalarını geri yayarak doğru sonuçlara ulaşmasını sağlayan kritik bir tekniktir.
- Backpropagation, bir sinir ağının çıktısı ile istenen sonuç arasındaki farkı (**hata**) minimize etmek için kullanılan bir yöntemdir. Bu süreç, modelin çıktılarında yapılan hataları geri yayarak, ağın her bir ağırlığını optimize etme işlemini içerir.
- **Neural networks (sinir ağları)**, katmanlar halinde düzenlenmiş nöronlardan oluşur ve bu katmanlar arasındaki bağların kuvvetleri (**ağırlıklar**) modeli tanımlar. Backpropagation, bu ağırlıkları güncelleyerek modelin öğrenmesini sağlar.
- Örneğin, bir sinir ağı bir görüntüdeki nesneyi tanımaya çalıştığında, modelin yaptığı hata hesaplanır ve bu hata, ağın önceki katmanlarına geri iletilir. Bu geri iletim süreci, hatanın hangi bağlantılardan kaynaklandığını belirler ve her bir bağlantının ağırlığı buna göre güncellenir.

[Kaynak](https://www.linkedin.com/pulse/feedforward-vs-backpropagation-ann-saffronedge1/)

---

## Backpropagation Nasıl Çalışır?

Backpropagation algoritması, temelde dört adımdan oluşur:

### 1. İleri Yayılım (Forward Propagation)
- Veri, sinir ağına giriş katmanından girer ve ağırlıklar aracılığıyla katmanlar arasında ilerleyerek bir çıktı üretir.
- Modelin mevcut durumu hakkında bir tahminde bulunmasını sağlar.
- Ancak bu aşamada, modelin ürettiği sonuç, doğru sonuca kıyasla hatalı olabilir.

### 2. Hata Hesaplama (Error Calculation)
- Modelin ürettiği çıktı ile doğru cevap (etiket) arasındaki fark hesaplanır.
- **Loss Function (kayıp fonksiyonu)** adı verilen bir formülle hata hesaplanır.
- En yaygın kullanılan kayıp fonksiyonlarından biri **Mean Squared Error (MSE)**'dir.

### 3. Hata Geri Yayılımı (Backpropagation)
- Hesaplanan hata, ağın son katmanından başlayarak önceki katmanlarına doğru geri yayılır.
- Hata, **zincir kuralı** kullanılarak katmanlar boyunca hesaplanır.
- Her bağlantının ne kadar katkıda bulunduğu belirlenir.

### 4. Ağırlık Güncelleme (Weight Update)
- Hata geri yayılımı tamamlandıktan sonra, her bağlantının ağırlığı güncellenir.
- **Gradient Descent** algoritması ile güncelleme yapılır.
- Ağırlıkların hangi yönde değişmesi gerektiği belirlenir ve modelin hatayı minimize edecek şekilde öğrenmesi sağlanır.
- Bu adımlar her öğrenme döngüsünde tekrarlanır ve modelin doğruluğu artar.

---
---

# Sigmoid Fonksiyonu

## **Sigmoid Fonksiyonu Nedir?**

- **Sigmoid Fonksiyonu**, sürekli bir gerçek sayıyı \( (0, 1) \) aralığına dönüştüren matematiksel bir fonksiyondur.
- Genellikle sinir ağlarında **aktivasyon fonksiyonu** olarak kullanılır. Küçük giriş değerleri **0'a yakın** çıktılar üretirken, büyük giriş değerleri **1'e yakın** çıktılar ile sonuçlanır.

Matematiksel gösterimi şu şekildedir:

\[ 
S(x) = \frac{1}{1 + e^{-x}} 
\]

---

## **Sigmoid Fonksiyonunun Özellikleri**

- \( x \) **küçük olduğunda**, sigmoid fonksiyonunun değeri **0'a yakındır**.
- \( x \) **büyük olduğunda**, sigmoid fonksiyonunun değeri **1'e yakındır**.
- Sigmoid fonksiyonu, sürekli **gerçek sayıları** belirli bir aralığa dönüştürerek **ağırlıkların daha kararlı** olmasını sağlar.

### **Sigmoid Fonksiyonunun Grafiği**
Sigmoid fonksiyonunun grafiği aşağıdaki gibidir:

![Sigmoid Grafiği](https://upload.wikimedia.org/wikipedia/commons/8/88/Logistic-curve.svg)

Kaynak: [Wikipedia](https://en.wikipedia.org/wiki/Sigmoid_function)

---

## **Sigmoid Aktivasyon Fonksiyonu**

- **Sigmoid aktivasyon fonksiyonu**, sinir ağlarında **makine öğrenimi** uygulamalarında yaygın olarak kullanılır.
- Bir sinir ağındaki her katmanı, bir **girdi vektörü** alan ve bir **çıktı vektörü** üreten bir matris olarak düşünebiliriz.
- Sinir ağları, bu tür **matris çarpımlarının** birbirine **zincirlenmesiyle** oluşturulur.
- Makine öğreniminde, bir **aktivasyon fonksiyonu**, her matris çarpımından sonra doğrusal olmayan bir fonksiyon uygular. Böylece, ağ sadece **doğrusal ilişkileri değil, tüm işlevsel ilişkileri** öğrenebilir.

---

## **Kaynakça**
- [Science Direct](https://www.sciencedirect.com/topics/computer-science/sigmoid-function)
- [Built In](https://builtin.com/machine-learning/sigmoid-activation-function)
- [Science Direct - Real Number](https://www.sciencedirect.com/topics/engineering/real-number)


## Backpropagation Algoritmasının Önemi

### 1. **Verimlilik**
- Sinir ağlarını eğitmek için hızlı ve etkin bir yol sunar.
- Milyonlarca parametrenin optimize edilmesini sağlar.

### 2. **Genel Kullanım Alanları**
- **Large Language Models (LLMs)**, **Convolutional Neural Networks (CNNs)** ve **Generative Adversarial Networks (GANs)** gibi modellerde kullanılır.
- **Attention mechanism** kullanan transformer yapıları bile bu algoritmadan faydalanır.

### 3. **Doğru Sonuçlara Ulaşma Yeteneği**
- Büyük veri setlerinden öğrenerek doğru tahminlerde bulunmayı sağlar.
- Hem basit hem de karmaşık problemleri çözebilir.

---

## Backpropagation Algoritmasının Zorlukları

- **Vanishing Gradient Problemi:** Çok derin sinir ağlarında, geri yayılım sırasında bazı katmanlardaki ağırlık güncellemeleri sıfıra çok yakın olabilir. Öğrenme sürecinin durmasına yol açar. **ReLU aktivasyon fonksiyonu** gibi modern tekniklerle aşılmaya çalışılır.
- **Exploding Gradient Problemi:** Gradient değerleri çok büyük olabilir ve bu da ağırlıkların kontrolsüz güncellenmesine yol açar. **Dikkatli optimizasyon ve ağırlık düzenleme teknikleri** ile çözülebilir.
- **Yüksek Hesaplama Gücü İhtiyacı:** Büyük sinir ağlarının eğitimi, güçlü donanımlar gerektirir.

[Kaynak](https://www.komtas.com/glossary/backpropagation-nedir)

---
---

# Image Processing (Görüntü İşleme)

## **Görüntü İşleme Nedir?**

- **Dijital görüntü işleme**, bilgisayar algoritmaları kullanılarak dijital görüntülerin işlenmesiyle ilgilenen yöntemler bütünüdür.
- **Yüz tanıma, nesne algılama ve görüntü sıkıştırma** gibi birçok uygulamada temel bir ön işleme adımıdır.
- Mevcut bir görüntüyü **geliştirmek** veya **önemli bilgileri ayıklamak** için kullanılır.
- **Derin öğrenme tabanlı bilgisayar görüşü** uygulamalarında, görüntü işleme **modelin performansını önemli ölçüde artırabilir**.

---

## **Görüntü Türleri / Makineler Görüntüleri Nasıl “Görüyor”?**

- **Dijital görüntüler**, bir bilgisayar tarafından **2B veya 3B matrisler** olarak yorumlanır.
- Matris içindeki her değer (**piksel**), **pikselin yoğunluğunu** temsil eder.
- Genellikle **0 ila 255** arasında değişen **8 bitlik görüntüler** ile çalışılır.
- **Fonksiyon gösterimi:**
  - **İkili veya gri tonlamalı görüntüler için:** \( I(x, y) \)
  - **RGB görüntüler için:** \( I(x, y, z) \)
- Burada:
  - **I** → Piksel yoğunluğunu ifade eder.
  - **(x, y) veya (x, y, z)** → Görüntüdeki pikselin koordinatlarını temsil eder.

---

## **Kaynakça**
- [V7 Labs - Image Processing Guide](https://www.v7labs.com/blog/image-processing-guide#what-is-image-processing)



